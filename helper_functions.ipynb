{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ce3cff-df3c-4a5d-bed1-42a2fdff7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce56d1-a327-43d9-9d0f-eb4e7179da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords that don't add value. Use this only for the wordcloud generation. \n",
    "stop_words = set(STOPWORDS)\n",
    "# print(list(stop_words)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f30bb-9ae2-421e-9e29-aec79b4ddfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, datetime_colname=''):\n",
    "    \"\"\"Load data using pandas. Don't use for large datasets.\n",
    "    Input-> path (required), datetime_colname (optional)- if passed, this col will be converted to datetime based on inference.\n",
    "    Output-> a pandas df\n",
    "    \"\"\"\n",
    "    \n",
    "    if '.csv' in path:\n",
    "        df = pd.read_csv(path, header= 0)\n",
    "        df = df.dropna(how='all') # drop records where all columns have null value\n",
    "        print(\"Columns :\" , df.columns,\"\\n\")\n",
    "        print(\"Rows    :\" , df.shape[0],\"\\n\")\n",
    "        \n",
    "    elif '.json' in path:    \n",
    "        try:\n",
    "            df = pd.read_json(path)\n",
    "            df = df.dropna(how='all') # drop records where all columns have null value\n",
    "            print(\"Columns :\" , df.columns,\"\\n\")\n",
    "            print(\"Rows    :\" , df.shape[0],\"\\n\")\n",
    "        \n",
    "        except:\n",
    "            df = pd.read_json(path, lines=True)\n",
    "            df = df.dropna(how='all') # drop records where all columns have null value\n",
    "            print(\"Columns :\" , df.columns,\"\\n\")\n",
    "            print(\"Rows    :\" , df.shape[0],\"\\n\")\n",
    "            \n",
    "    \n",
    "    if datetime_colname != '':\n",
    "        df[datetime_colname] = pd.to_datetime(df[datetime_colname])\n",
    "        df = df.sort_values(datetime_colname, ascending=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ac0dd-7e86-4edd-a297-6c6c185a0dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data (optional) \n",
    "def filter_data(df, colname, limiting_val, condition_val):\n",
    "    \"\"\"Input: pandas df, col to filter on, limiting_val to filter data, condition_val one of ('greater than', 'less_than')\n",
    "       Output: filtered pandas df \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if condition_val == 'greater than':\n",
    "            condition = df[f'{colname}'] > limiting_val\n",
    "            df = df[condition]\n",
    "            print(f\"Filtered data shape : {df.shape}\")\n",
    "        elif condition_val == 'less_than':\n",
    "            condition = df[f'{colname}'] < limiting_val\n",
    "            df = df[condition]\n",
    "            print(f\"Filtered data shape : {df.shape}\")      \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(e.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d0864-9c77-46c2-be29-facee7a8c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_wordclouds(df, textcolumnname, nafillvalue=''):\n",
    "    \"\"\" Function to generate word clouds based on a pandas text column\n",
    "        Input: a pandas df, a textual column, fill value (optional) if nulls in column\n",
    "        Output: a wordcloud based on text column (minus stopwords) \"\"\"\n",
    "    \n",
    "    if df[textcolumnname].isna().sum() != 0:\n",
    "        print(\"Null count\", df[textcolumnname].isna().sum())\n",
    "        print(\"Text column cannot have nulls. Dtype error. Fix float -> str\")\n",
    "        print(\"Either fill na or don't plot NA data (defaults to not plot NAs)\")\n",
    "        \n",
    "        df1 = df.copy(deep=True)\n",
    "        try:\n",
    "            nafillvalue == ''\n",
    "            df1 = df.loc[df[textcolumnname].notna()]\n",
    "            \n",
    "        except:\n",
    "            df1[textcolumnname].fillna(nafillvalue, inplace=True)\n",
    "    \n",
    "    else:\n",
    "        df1 = df.copy(deep=True)\n",
    "\n",
    "    text_data_to_generate = ''.join(df1[textcolumnname])\n",
    "    wordcloud = WordCloud(stopwords = stop_words, width=1600 , height=800,background_color=\"White\",colormap=\"Set2\").generate(text_data_to_generate)\n",
    "    plt.ion()\n",
    "    plt.figure(figsize=(20,10),facecolor='k')\n",
    "    plt.imshow(wordcloud,interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ade222-b1a4-4740-a0a1-6434bf0f7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dist_series(df, colname):\n",
    "    \"\"\" Inputs -> pandas df, numeric col to plot \"\"\"\n",
    "    try:\n",
    "        return df.plot.hist(column=colname , title= df.name) # , by ='Product'\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e.args)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c02edb4-ef31-4836-bfbb-ed967e3197da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_groupby(df, columnname):\n",
    "    \"\"\" Find all unique values in a column and create datasets for each grouping \n",
    "        Input: pandas df, columnname for which values need to be grouped \n",
    "        Output: a list of pandas dataframes, a pandas series with df sizes at same indexes (use pd.concat(list_of_dfs) to union). Each df in list is named by the group value\"\"\"\n",
    "    \n",
    "    uniques_vals = list(df[columnname].unique())\n",
    "    list_of_dfs = [] \n",
    "    sizes = []\n",
    "    for grp in uniques_vals:\n",
    "    \n",
    "        grouped_df = data.loc[data[columnname] == grp]\n",
    "        grouped_df.name = grp\n",
    "        \n",
    "        list_of_dfs.append(grouped_df)\n",
    "        \n",
    "        sizes.append(grouped_df.shape[0])\n",
    "        \n",
    "    return list_of_dfs, pd.Series(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784995a3-9057-4d81-9526-fdfa4bbb1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_data(list_of_dfs, sizes, textcolumn, numcolumn, to_limit=False, n_limit=20):\n",
    "    \"\"\"Takes as input a list of dataframes and sizes of dataframes and prints dist of numeric column and wordcloud for textcolumn. Doesn't return anything\n",
    "       Input: list of pandas dfs, pandas series with sizes of the dfs (same order), textcolumn name, numcolumn name, to_limit whether to limit the plotting to first n_limit dfs (desc), n_limit \"\"\"\n",
    "    \n",
    "    index_by_largest_record_counts = sizes.sort_values(ascending=False).index.values\n",
    "    \n",
    "    if to_limit :\n",
    "        limit_returned_results = index_by_largest_record_counts[ : n_limit]  # ignore this if list_of_dfs size is not very large. \n",
    "        \n",
    "        for i in np.array(list_of_dfs)[limit_returned_results]:\n",
    "            print(i.name)\n",
    "            plot_dist_series(i, numcolumn)\n",
    "            gen_wordclouds(i, textcolumn)\n",
    "            \n",
    "    else:\n",
    "        for i in np.array(list_of_dfs)[index_by_largest_record_counts]:\n",
    "            print(i.name)\n",
    "            plot_dist_series(i, numcolumn)\n",
    "            gen_wordclouds(i, textcolumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b507d798-db71-45a1-8bf3-e2a79a398776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(df, textcolname):\n",
    "    \"\"\" Function to get polarity [-1,1] and subjectivity[0,1] from a text using TextBlob\n",
    "        Input: pandas df, text col name to get sentiment\n",
    "        Output: pandas df with 2 sentiment columns- sentiment_polarity, sentiment_subjectivity \"\"\"\n",
    "    \n",
    "    \n",
    "    data.loc[data[textcolname].notna() , 'sentiment_polarity'] = data[data[textcolname].notna()][textcolname].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    data.loc[data[textcolname].notna() , 'sentiment_subjectivity'] = data[data[textcolname].notna()][textcolname].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "    \n",
    "    return data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
